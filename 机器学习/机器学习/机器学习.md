# 概述
1-2：机器学习基础知识。
一、机器学习基础
1.	绪论
- 核心概念：属性/特征、样本/示例、标记、数据集（训练集/测试集）、假设空间、归纳偏好、奥卡姆剃刀、NFL定理（No Free Lunch）。
- 关系：定义学习任务的基本要素，假设空间搜索是模型生成的基础，归纳偏好（如奥卡姆剃刀）引导模型选择，NFL定理强调算法优劣需结合具体问题。
2.	模型评估与选择
- 核心概念：过拟合/欠拟合、交叉验证（k折、留一法）、自助法、性能度量（准确率、查准率、查全率、F1、ROC-AUC）、偏差-方差分解（泛化误差的三大来源）。
- 关系：评估方法解决模型泛化能力验证问题，性能度量指导模型优化方向，偏差-方差分解揭示了模型复杂性与数据扰动间的平衡需求。

3-10：经典常用的机器学习方法。
二、核心模型与技术
3.	线性模型
- 核心概念：最小二乘法（线性回归）、对数几率回归（分类）、线性判别分析（LDA）、类别不平衡处理（再缩放/阈值移动）。
- 关系：线性回归通过最小化均方误差拟合连续值，对数几率回归引入Sigmoid函数扩展至分类任务，LDA通过投影优化类间分离度。
4.	决策树
- 核心概念：信息增益、增益率、基尼指数（划分准则）、预剪枝/后剪枝、连续值处理、多变量决策树。
- 关系：划分准则决定节点分裂方式，剪枝策略控制过拟合，多变量决策树通过线性组合提升表达能力。
5.	神经网络与深度学习
- 核心概念：M-P神经元、感知机（线性分类）、多层前馈网络（BP算法）、梯度消失、卷积神经网络（权共享）、深度学习（无监督逐层预训练）。
- 关系：感知机是神经网络基础，BP算法通过误差反向传播优化参数，深度学习通过增加隐层与权共享解决复杂特征提取。
6.	支持向量机（SVM）
- 核心概念：间隔最大化、对偶问题、核函数（非线性映射）、软间隔（容忍噪声）、支持向量回归（SVR）。
- 关系：核函数将低维不可分数据映射到高维空间，软间隔与核方法共同提升模型鲁棒性。
7.	贝叶斯分类器
- 核心概念：贝叶斯决策论、生成式 vs 判别式模型、朴素贝叶斯（属性条件独立）、EM算法（隐变量估计）。
- 关系：朴素贝叶斯是生成式模型的代表，EM算法用于含隐变量的概率模型参数估计（如高斯混合聚类）。
8.	集成学习
- 核心概念：Boosting（AdaBoost，关注降低偏差）、Bagging（随机森林，降低方差）、多样性度量、误差-分歧分解。
- 关系：集成通过组合弱学习器提升整体性能，Boosting与Bagging分别从序列加权和并行采样角度增强多样性。

11-16：进阶知识。
三、高级专题
9.	聚类与降维
- 核心概念：
- 聚类：原型聚类（K均值）、密度聚类（DBSCAN）、层次聚类（AGNES）
- 降维：主成分分析（PCA）、核化PCA（KPCA）、流形学习（Isomap、LLE）。
- 关系：聚类揭示数据内在结构，降维通过压缩特征维度缓解维度灾难，两者均属无监督学习。
10.	概率图模型
- 核心概念：贝叶斯网（有向图）、马尔可夫网（无向图）、隐马尔可夫模型（HMM）、条件随机场（CRF）。
- 关系：图结构表达变量间的依赖关系，HMM用于序列标注，CRF解决HMM的标记偏置问题。
11.	半监督与强化学习
- 核心概念：
- 半监督：生成式方法、图半监督（标签传播）、协同训练
- 强化：马尔可夫决策过程（MDP）、Q-learning、策略迭代。
- 关系：半监督学习利用未标记数据提升泛化，强化学习通过环境交互优化长期奖励策略。

# 1、绪论

---

机器学习：通过计算的手段，利用经验改善系统自身的性能。

---

学习算法：从数据中产生模型的算法。
数据集：记录的集合。
示例、样本：关于事件或对象的描述的记录。
属性、特征：反映事物或对象在某方面的表现或性质。
属性值：属性上的取值。
属性空间、样本空间、输入空间：属性张成的空间。
一个示例称为一个特征向量。
D为包含m个示例的数据集，每个示例有d个属性描述，d称为样本的维数。
训练过程：训练数据、训练样本、训练集。
学得模型对应了关于数据的某种潜在的规律，因此亦称假设。
潜在规律本身，称为真相或真实。
模型可称为学习器。
示例结果的信息：标记。
拥有了标记信息的示例：样例。
标记的集合：标记空间或输出空间。
离散值分类、连续值回归。
只涉及两个类别的二分类，其中一个为正类，另一个为反类。
涉及多个类别为多分类。
学得模型后对其预测的过程称为测试。
聚类：将训练数据分为若干组，每组称为一个簇。
根据训练数据是否有标记信息，分为监督学习和无监督学习。
学得模型适用于新样本的能力：泛化能力。
通常假设样本空间的全体样本服从一个未知的分布，每个样本都是独立地采样获得的，称为独立同分布。

---

归纳：特殊到一般的泛化过程。
演绎：一般到特殊的特化过程。
从样例中学习：归纳学习。
学习：在所有假设组成的空间进行搜索的过程，搜索目标是找到与训练集匹配的假设。
版本空间：有多个假设与训练集一致，与训练集一致的假设集合。

---

归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好。
奥卡姆剃刀：多个假设与观察一致时选最简单的那个。
NFL定理：要谈论算法的优劣，必须要针对具体的学习问题。

---

# 2、模型评估与选择

---

分类任务：
错误率：分类错误的样本数占样本总数的比例。
精度=1-错误率。
误差：预测输出与真实输出的差异、训练误差或经验误差：训练集上的误差、泛化误差：新样本上的误差。

过拟合：把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，泛化性能下降。
欠拟合：训练样本的一般性质尚未学好。
欠拟合容易克服，过拟合无法避免。

模型选择问题：选用哪一种学习算法，使用哪一种参数配置。

---

评估方法：测试集、测试误差。

留出法：直接将数据集D划分为两个互斥的集合，一个作为训练集，一个作为测试集。
分层采样：保持类别比例的采样方式。
一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

交叉验证法：划分为k个集合，每次将k-1个集合作为训练集，剩下的一个集合作为测试集，重复k次，又称k折交叉验证。k最常用取值为10。

自助法：以自助采样法作为基础，m个样本，随机重复采样m次得到D'，D'作为训练集，D/D'作为测试集。

调参：对算法参数进行设定。
现实中常用的做法，是对每个参数选定一个范围和变化步长，从几个候选值中产生选定值。

模型评估与选择中用于评估测试的数据集称为称为验证集。

---

性能度量：衡量模型泛化能力的评价标准。

回归任务中最常用的性能度量是均方误差。
分类任务中最常用的性能度量是错误率和精度。
查准率、查全率、P-R图和F1。
ROC、AUC。
代价敏感错误率、代价曲线。

---

学习器性能比较：统计假设检验。
基于统计假设检验，我们可以推断出，若在测试集上观察到学习器A比B好，那么学习器A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。

单个学习器泛化性能：
一次留出法：二项检验。
多次重复留出法或交叉验证等：t检验。

两个学习器，可以用k折交叉验证的成对t检验。
二分类问题：McNemar检验。

一组数据集多个算法比较：
Friedman检验。Nemenyi后续检验。

---

泛化误差可分解为偏差、方差与噪声之和。
偏差与方差是有冲突的，称为偏差-方差窘境。

---

# 3、线性模型

---

f=wx+b

线性模型有很好的可解释性。
非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。

---

线性回归试图学得一个线性模型尽可能准确地预测实值输出标记。
最小二乘法：均方误差最小化。
广义线性模型。

---

分类任务：找一个单调可微函数将分类任务的真实标记与线性回归模型的预测值联系起来。

---

线性判别分析（LDA）：给定训练样例集，设法将样例投射到一条直线上，使得同类样例的投影点尽可能近，异类样例的投影点尽可能远。在对新样本进行分类时将其投射到同样的这条直线上，根据投影点的位置来确定新样本的类别。

---

多分类学习的基本思路是拆解法。将多分类任务拆分为若干个二分类任务求解。
一对一，一对多，多对多。


---

类别不平衡问题：分类任务中不同类别的样例数目差别很大。
再缩放。
欠采样、过采样、阈值移动。

---

# 4、决策树

---

决策树基于树结构进行决策。
一般的，一棵决策树包含一个根节点，若干个内部节点，若干个叶节点。叶节点对应于决策结果，其他每个节点则对应于一个属性测试。每个节点包含的样本集合根据属性测试的结果被划分到子节点中。根节点包含样本全集。从根节点到每个叶节点的路径对应了一个判定测试序列。决策树学习的目的是为了产生一棵泛化能力强的决策树。其基本流程遵循简单且直观的分而治之策略。

---

一般而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的纯度越来越高。
信息熵，信息增益，增益率，基尼指数。

---

剪枝处理
预剪枝、后剪枝。

---

连续值处理、缺失值处理。

---

多变量决策树。

---

# 5、神经网络

---

神经网络最基本的模型：神经元模型。神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。
把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。

---

感知机由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，亦称阈值逻辑单元。
感知机能容易地实现逻辑与、或、非运输。
感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非常有限。
若两类模式是线性可分的，则感知机的学习过程一定会收敛。否则感知机学习过程将会发生振荡。
要解决非线性可分问题，需考虑使用多层功能神经元。
输出层与输入层之间的神经元，被称为隐层或隐含层。
隐含层与输出层神经元都是拥有激活函数的功能神经元。
多层前馈神经网络：每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接的神经网络。
神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。

---

BP算法。
缓解BP网络的过拟合：早停或正则化。

---

全局最小与局部最小。
跳出局部最小的策略：
以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。
模拟退火技术。
随机梯度下降。

---

RBF网络、ART网络、SOM网络、级联相关网络、elman网络、boltzmann机。

---

深度学习

---

# 6、支持向量机

---

分类学习中，基于训练集在样本空间寻找划分超平面，将不同类别的样本分开。
最大间隔。

---

对偶问题

---

核函数

在现实任务中，原始样本空间内也许并不存在一个能正确划分两类样本的超平面。可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。

软间隔与正则化

---

支持向量回归

---

核方法

---

# 7、贝叶斯分类器

---

贝叶斯决策论是概率框架下实施决策的基本方法。
对分类任务来说，在所有相关概率都已知的理想情况下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。














---





# 8、集成学习

---

集成学习通过构建并结合多个学习器来完成学习任务，也被称为多分类器系统、基于委员会的学习。

集成学习的一般策略：先产生一组个体学习器，再用某种策略将它们结合起来。

同质集成







# 9、聚类




















# 10、降维与度量学习
k近邻学习：给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测。分类任务投票法，回归任务平均法，还可基于距离远近进行加权-平均或加权投票。
懒惰学习：在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到测试样本后再进行处理。
急切学习：训练阶段就对样本进行学习处理的方法。
最近邻分类器虽然简单，但它的泛化错误率不超过贝叶斯最优分类器的错误率的两倍。

密采样：训练样本的采样密度足够大。

在高维情况下出现的数据样本稀疏、距离计算困难等问题，是所有机器学习方法共同面临的严重障碍，被称为维数灾难。
缓解维数灾难的一个重要途径是降维，即通过某种数学变换将原始高维属性空间转变为一个低维子空间，在这个子空间中样本密度大幅提高，距离计算也变得更为容易。
很多时候，人们观测或收集到的数据样本虽然是高维的，但与学习任务密切相关的也许仅仅是某个低维分布，即高维空间中的一个低维嵌入。

多维缩放：要求原始空间中样本之间的距离在低维空间中得以保持。

一般来说，欲获得低维子空间，最简单的是对原始高维空间进行线性变换。
基于线性变换来进行降维的方法称为线性降维方法。它们都符合基本形式，不同之处是对低维子空间的性质有不同的要求。

对降维效果的评估，通常是比较降维前后学习器的性能，若性能有所提高，则认为降维起到了作用。若将维数降至二维或三维，则可通过可视化技术来直观地判断降维效果。

主成分分析：满足最近重构性，最大可分性。
最近重构性：样本点到这个超平面的距离都足够近。
最大可分性：样本点在这个超平面上的投影尽可能分开。

本真低维空间：原本采样的低维空间。

PCA仅需保留W与样本的均值向量即可通过简单的向量减法和矩阵-向量乘法将新样本投影至低维空间。

显然，低维空间与高维空间必有不同。因为对应与最小的d-d'个特征值的特征向量被舍弃了。一方面，舍弃这部分信息之后能使样本的采样密度增大。另一方面，当数据收到噪声影响时，最小的特征值所对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到去噪的效果。

不少现实任务中，可能需要非线性映射才能找到恰当的低维嵌入。

非线性降维的一种常用方法，是基于核技巧对线性降维方法进行核化。

![alt text](image-2.png)

![alt text](image-3.png)


机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中进行学习能比原始空间性能更好。事实上，每个空间对应了在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一个合适的距离度量。
度量学习：直接尝试学习出一个合适的距离度量。


# 11、特征选择与稀疏学习








# 12、计算学习理论








# 13、半监督学习









# 14、概率图模型

---





隐马尔可夫模型是结构最简单的动态贝叶斯网，这是一种著名的有向图模型。

---

马尔可夫随机场


---

条件随机场是一种判别式无向图模型。
条件随机场试图对多个变量在给定观测值后的条件概率进行建模。

---

学习与推断
基于概率图模型定义的联合概率分布，我们能对目标变量的边际分布或以某些可观测变量为条件的条件分布进行推断。
边际分布是指对无关变量求和或积分得到结果。
概率图模型的推断方法大致可分为两类，第一类是精确推断方法，希望能计算出目标变量的边际分布或条件分布的精确值。一般情况下，此类算法的计算复杂度随着极大团数量的增长呈指数增长，适用范围有限。第二类是近似推断方法，希望在较低的时间复杂度下获得原问题的近似解。

变量消去，信念传播。

---

近似推断方法大致可分为两大类：第一类是采样，通过使用随机化方法完成近似。第二类是使用确定性近似完成近似推断，典型代表为变分推断。

MCMC采样，变分推断。

---

话题模型是一族生成式有向图模型，主要用于处理离散型的数据。隐狄利克雷分配模型是话题模型的典型代表。
词是待处理数据的基本离散单元，文档是待处理的数据对象，它由一组词组成，这些词在文档中是不计顺序的。
这样的表示方式称为词袋。
话题表示为一个概念，具体表示为一系列相关的词，以及它们在该概念下出现的概率。

---

# 15、规则学习

---

规则：语义明确，能描述数据分布所隐含的客观规律或领域概念，可写成若......则......形式的逻辑规则
规则学习：从训练数据中学习出一组能用于对未见示例进行判别的规则。

逻辑蕴含符号左边规则头表示该条规则的结果，右边规则体表示该条规则的前提。
规则体是由逻辑文字f组成的合取式。

符合规则的样本称为被该规则覆盖。

当同一示例被判别结果不同的多条规则覆盖时，称发生了冲突，解决冲突的办法叫冲突消解，有投票法，排序法，元规则法等。

默认规则：处理规则集合未覆盖的样本。

---

序贯覆盖：即逐条归纳，在训练集上每学习到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。
每次只处理一部分数据，也称分治策略。

现实任务中一般有两种策略来产生规则：自顶向下，自底向上。

---

剪枝优化
预剪枝，后剪枝。

---

一阶规则学习
FOIL

---

归纳逻辑程序设计：在一阶规则学习中引入了函数和逻辑表达式嵌套。
最小一般泛化。
逆归结。

---

# 16、强化学习

---

强化学习任务通常用马尔可夫决策过程来描述：机器处于环境E中，状态空间为X，每个状态x是机器感知到的环境的描述。机器能采取的动作构成了动作空间A。若某个动作作用于当前状态x上，则潜在的转移函数P将使得环境从当前状态按某种概率转移到另一个状态。在转移到另一个状态的同时，环境会根据潜在的奖赏函数R反馈给机器一个奖赏。
机器要做的是通过在环境中不断地尝试而学得一个策略，根据这个策略，在状态x下就能得知要执行的动作a。

策略有两种表示方式，一种是将策略表示为函数，另一种是概率表示。
策略的优劣取决于长期执行这一策略后得到的累计奖赏。强化学习任务中，学习的目的就是要找到能使长期累积奖赏最大化的策略。
长期累积奖赏有多种计算方式，常用的有T步累积奖赏和γ折扣累积奖赏。

强化学习与监督学习的区别：状态对应示例，动作对应标记，强化学习中的策略实际上就相当于监督学习中的分类器或回归器，模型的形式并无差别。
强化学习中并没有监督学习中的有标记样本。换言之，没有人告诉机器在上面状态下应该做什么动作，只有等到最终结果揭晓，才能通过反思之前的动作是否正确来进行学习。因此，强化学习在某种意义上可看作具有延迟标记信息的监督学习问题。

---

单步强化学习任务：K摇臂赌博机。
策略：仅探索，仅利用。
事实上，探索和利用这两者是矛盾的，因为尝试次数有限，加强了一方则会自然削弱另一方。

- ε贪心：概率ε探索，否则利用。
- Softmax：基于已知的平均奖赏来对探索和利用进行折中。若平均奖赏相当，则选取概率也相当；若某些摇臂的平均奖赏明显更高，则被选取的概率也明显更高。

---

有模型学习：在已知模型的环境中学习。
策略评估、策略改进、策略迭代。

---

免模型学习：学习算法不依赖于环境建模。
- 蒙特卡罗强化学习：多次采样，求取平均累积奖赏来作为期望累积奖赏的近似。
- 时序差分学习：结合动态规划和蒙特卡罗方法的思想。
- 值函数近似。

---

从样例中学习：模仿学习。
- 直接模仿学习：直接模仿人类专家的“状态-动作对”。
- 逆强化学习：从人类专家提供的范例数据中反推出奖赏函数。

---
