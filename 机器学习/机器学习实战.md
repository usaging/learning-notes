# 第一部分 机器学习的基础知识

## 什么是机器学习，为什么使用机器学习

机器学习是一门通过编程让计算机从数据中进行学习的科学（和
艺术）。
系统用来进行学习的样例称作训练集。每个训练样例称作训练实例（或样本）。
机器学习适用于：

- 有解决方案（但解决方案需要进行大量人工微调或需要遵循大量规则）的问题：机器学习算法通常可以简化代码，相比传统方法有更好的性能。
- 传统方法难以解决的复杂问题：最好的机器学习技术也许可以找到解决方案。
- 环境有波动：机器学习算法可以适应新数据。
- 洞察复杂问题和大量数据。

## 机器学习系统的类型

现有的机器学习系统类型繁多，为便于理解，我们根据以下标准将
它们进行大的分类：

- 是否在人类监督下训练（有监督学习、无监督学习、半监督学习和强化学习）。
- 是否可以动态地进行增量学习（在线学习和批量学习）。
- 是简单地将新的数据点和已知的数据点进行匹配，还是像科学家那样，对训练数据进行模式检测然后建立一个预测模型（基于实例的学习和基于模型的学习）。

### 监督学习和无监督学习
根据训练期间接受的监督数量和监督类型，可以将机器学习系统分为以下四个主要类别：有监督学习、无监督学习、半监督学习和强化学习。
有监督学习
在有监督学习中，提供给算法的包含所需解决方案的训练集称为标签。
分类任务是一个典型的有监督学习任务。
另一个典型的任务是通过给定一组称为预测器的特征（里程、使用年限、品牌等）来预测一个目标数值（例如汽车的价格）。这种类型的任务称为回归。

在机器学习里，属性是一种数据类型，而特征通常状况下，意味着一个属性加上其值。
值得注意的是，一些回归算法也可以用于分类任务，反之亦然。例如，逻辑回归就被广泛地用于分类，因为它可以输出“属于某个给定类别的概率”的值。

一些最重要的有监督学习算法：

- k-近邻算法
- 线性回归
- 逻辑回归
- 支持向量机（SVM）
- 决策树和随机森林
- 神经网络

无监督学习
顾名思义，无监督学习的训练数据都是未经标记的。

一些最重要的无监督学习算法：
- 聚类算法
- k-均值算法
- DBSCAN
- 分层聚类分析（HCA）
- 异常检测和新颖性检测
- 单类SVM
- 孤立森林
- 可视化和降维
- 主成分分析（PCA）
- 核主成分分析
- 局部线性嵌入（LLE）
- t-分布随机近邻嵌入（t-SNE）
- 关联规则学习
- Apriori
- Eclat

聚类算法检测相似的分组。
可视化算法利用大量复杂的、未标记的数据，轻松绘制输出2D或3D的数据表示。这些算法会尽其所能地保留尽量多的结构（例如，尝试保持输入的单独集群在可视化中不会被重叠），以便于理解这些数据是怎么组织的，甚至识别出一些未知的模式。
降维的目的是在不丢失太多信息的前提下简化数据。方法之一是将多个相关特征合并为一个。这个过程叫作特征提取。

通常比较好的做法是，先使用降维算法减少训练数据的维度，再将其提供给另一个机器学习算法（例如有监督学习算法）。这会使它运行得更快，数据占用的磁盘空间和内存都会更小，在某些情况下，执行性能也会更高。
异常检测，系统用正常实例进行训练，然后当看到新的实例时，它就可以判断出这个新实例看上去是正常还是异常。
新颖性检测。它的目的是检测看起来与训练集中的所有实例不同的新实例。

关联规则学习，其目的是挖掘大量数据，发现属性之间的有趣联系。

半监督学习
由于通常给数据做标记是非常耗时和昂贵的，你往往会有很多未标记的数据而很少有已标记的数据。有些算法可以处理部分已标记的数据。这被称为半监督学习。
![alt text](image.png)
半监督学习有两个类别（三角形和正方形）：未标记的示例（圆形）有助于将新实例（十字）分类为三角形类别而不是正方形类别，即使它更接近于标记的正方形。
大多数半监督学习算法是无监督算法和有监督算法的结合。

强化学习
强化学习的学习系统（在其语境中称为智能体）能够观察环境，做出选择，执行动作，并获得回报（或者是以负面回报的形式获得惩罚）。所以它必须自行学习什么是最好的策略，从而随着时间的推移获得最大的回报。策略代表智能体在特定情况下应该选择的动作。

### 批量学习和在线学习
另一个给机器学习系统分类的标准是看系统是否可以从传入的数据流中进行增量学习。
批量学习
在批量学习中，系统无法进行增量学习——即必须使用所有可用数据进行训练。这需要大量时间和计算资源，所以通常都是离线完成的。
离线学习就是先训练系统，然后将其投入生产环境，这时学习过程停止，它只是将其所学到的应用出来。

如果希望批量学习系统学习新数据，需要在完整数据集（包括新数据和旧数据）的基础上重新训练系统的新版本，然后停用旧系统，用新系统取而代之。幸运的是，整个训练、评估和启动机器学习系统的过程可以很轻易地实现自动化，所以即使是批量学习系统也能够适应变化。只是需要不断地更新数据，并根据需要频繁地训练系统的新版本。
这个解决方案比较简单，通常也都能正常工作，只是每次都使用完整数据集进行训练可能需要花上好几个小时，所以，很有可能会选择每天甚至每周训练一次新系统。如果系统需要应对快速变化的数据，那么你需要一个更具响应力的解决方案。
此外，使用完整数据集训练需要耗费大量的计算资源（CPU、内存空间、磁盘空间、磁盘I/O、网络I/O等）。如果数据量非常大，并且每天从零开始自动执行训练系统，那最终将为此花费大量的金钱。
而假如你面对的是海量数据，甚至可能无法再应用批量学习算法所以如果你的资源有限，而系统需要实现自主学习，那么像这样携带大量训练数据，占用大量资源，动辄每天耗费几小时来进行训练的方式，肯定会心有余而力不足。

在线学习
在在线学习中，你可以循序渐进地给系统提供训练数据，逐步积累学习成果。这种提供数据的方式可以是单独的，也可以采用小批量的小组数据来进行训练。每一步学习都很快速并且便宜，这样系统就可以根据飞速写入的最新数据进行学习。

对于这类系统——需要接收持续的数据流，同时对数据流的变化做出快速或自主的反应，使用在线学习是一个非常好的
方式。如果计算资源有限，在线学习同样也是一个很好的选择：新的数据实例一旦经过在线学习系统的学习，就不再需要，可以将其丢弃（除非想回滚到前一个状态，再“重新学习”数据），这可以节省大量的空间。
对于超大数据集——超出一台计算机的主存储器的数据，在线学习算法也同样适用（这称为核外学习）。算法每次只加载部分数据，并针对这部分数据进行训练，然后不断重复这个过程，直到完成所有数据的训练。

核外学习通常是离线完成的（也就是不在实时（live）系统上），因此在线学习这个名字很容易让人产生误解。我们可以将其视为增量学习。
在线学习系统的一个重要参数是其适应不断变化的数据的速度，这就是所谓的学习率。如果设置的学习率很高，那么系统将会迅速适应新数据，但同时也会很快忘记旧数据。反过来，如果学习率很低，系统会有更高的惰性，也就是说，学习会更缓慢，同时也会对新数据中的噪声或者非典型数据点（离群值）的序列更不敏感。
在线学习面临的一个重大挑战是，如果给系统输入不良数据，系统的性能将会逐渐下降。为了降低这种风险，你需要密切监控系统，一旦检测到性能下降，就及时中断学习（可能还需要恢复到之前的工作状态）。当然，同时你还需要监控输入数据，并对异常数据做出响应（例如，使用异常检测算法）。

### 基于实例的学习与基于模型的学习

另一种对机器学习系统进行分类的方法是看它们如何泛化。大多数机器学习任务是要做出预测。这意味着系统需要通过给定的训练示例，在它此前并未见过的示例上进行预测（泛化）。

泛化的主要方法有两种：基于实例的学习和基于模型的学习。
基于实例的学习
我们最司空见惯的学习方法就是简单地死记硬背。这虽然不是最差的解决方案，但肯定也不是最好的。除了完全相同的，还可以通过编程让系统比较数据之间的相似度。这被称为基于实例的学习：系统用心学习这些示例，然后通过使用相似度度量来比较新实例和已经学习的实例（或它们的子集），从而泛化新实例。

基于模型的学习
从一组示例集中实现泛化的另一种方法是构建这些示例的模型，然后使用该模型进行预测。这称为基于模型的学习。

在使用模型之前，需要先定义参数的值。怎么才能知道什么值可以使模型表现最佳呢？要回答这个问题，需要先确定怎么衡量模型的性能表现。要么定义一个效用函数（或适应度函数）来衡量模型有多好，要么定义一个成本函数来衡量模型有多差。
对于线性回归问题，通常的选择是使用成本函数来衡量线性模型的预测与训练实例之间的差距，目的在于尽量使这个差距最小化。

## 机器学习的主要挑战

训练数据的数量不足：对复杂问题而言，数据比算法更重要。
训练数据不具代表性：为了很好地实现泛化，至关重要的一点是对于将要泛化的新示例来
说，训练数据一定要非常有代表性。

如果样本集太小，将会出现采样噪声（即非代表性数据被选中）；而即便是非常大的样本数据，如果采样方式欠妥，也同样可能导致非代表性数据集，这就是所谓的采样偏差。

低质量数据：显然，如果训练集满是错误、异常值和噪声（例如，低质量的测量产生的数据），系统将更难检测到底层模式，更不太可能表现良好。

无关特征：只有训练数据里包含足够多的相关特征以及较少的无关特征，系统才能够完成学习。
一个成功的机器学习项目，其关键部分是提取出一组好的用来训练的特征集。这个过程叫作特征工程，包括以下几点：
·特征选择（从现有特征中选择最有用的特征进行训练）。
·特征提取（将现有特征进行整合，产生更有用的特征——正如前
文提到的，降维算法可以提供帮助）。
·通过收集新数据创建新特征。

过拟合训练数据：模型在训练数据上表现良好，但是泛化时却不尽如人意。

当模型相对于训练数据的数量和噪度都过于复杂时，会发生过拟合。可能的解决方案如下。
- 简化模型：可以选择较少参数的模型（例如，选择线性模型而不是高阶多项式模型）也可以减少训练数据中的属性数量，或者是约束模型。
- 收集更多的训练数据。
- 减少训练数据中的噪声（例如，修复数据错误和消除异常值）。

通过约束模型使其更简单，并降低过拟合的风险，这个过程称为正则化。
在学习时，应用正则化的程度可以通过一个超参数来控制。超参数是学习算法（不是模型）的参数。因此，它不受算法本身的影响。超参数必须在训练之前设置好，并且在训练期间保持不变。

欠拟合训练数据：欠拟合和过拟合正好相反。它的产生通常是对于底层的数据结构来说，模型太过简单。
解决这个问题的主要方式有：
- 选择一个带有更多参数、更强大的模型。
- 给学习算法提供更好的特征集（特征工程）。
- 减少模型中的约束（例如，减少正则化超参数）。

## 测试与验证
将数据分割成两部分：训练集和测试集。顾名思义，你可以用训练集的数据来训练模型，然后用测试集的数据来测试模型。应对新场景的误差率称为泛化误差（或者样例外误差），通过测试集来评估你的模型，就可以得到对这个误差的评估。这个估值可以告诉你模型在处理新场景时的能力如何。如果训练误差很低（模型对于训练集来说很少出错），但是泛化误差很高，那么说明你的模型对于训练数据存在过拟合。

超参数调整和模型选择
评估一个模型很简单：用测试集就行了。现在假设在两个模型（一个线性模型和一个多项式模型）之间犹豫不决，如何做出判断呢？做法是训练两个模型，然后对比它们对测试数据的泛化能力。
现在假设线性模型的泛化能力更强，但是想要应用一些正则化
来避免过拟合。问题又来了，要如何选择正则化超参数的值呢？做法之一是使用100个不同的超参数值来训练100个不同的模型。然后假设由此找到了最佳的超参数值，它生成的模型泛化误差最小，然后在生产环境中运行这个模型，可是很不幸，它并没有如预期那样工作，
问题出在测试集的泛化误差进行了多次度量，并且调整模型和超参数来得到拟合那个测试集的最佳模型。这意味着该模型对于新的数据不太可能有良好的表现。
解决此问题的常见方法称为保持验证：你只需保持训练集的一部分，以评估几种候选模型并选择最佳模型。新的保留集称为验证集，有时也称为开发集（dev set）。更具体地说，可以在简化的训练集上（即完整训练集减去验证集）训练具有各种超参数的多个模型，并且选择在验证集上表现最佳的模型。在此保持验证之后，在完整的训练集（包括验证集）上训练最佳模型，这就是最终模型。最后，在测试集上评估这个模型以获得泛化误差的估计值。

解决此问题的一种方法是执行使用许多小验证集重复进行的交叉验证。每个模型都在对其余数据进行训练后，在每个验证集上评估一次。通过对模型的所有评估求平均值，可以更准确地衡量模型的性能。但是有一个缺点：训练时间是验证集个数的倍数。

数据不匹配
在某些情况下，很容易获得大量训练数据，但是这些数据可能不能完全代表将用于生产环境的数据。
在这种情况下，最重要的规则是：验证集和测试集必须与在生产环境中使用的数据具有相同的代表性。
一种解决方案是将一些训练数据放到train-dev（训练开发）集中。训练模型后（在训练集而不是在train-dev集上），你可以在train-dev集上对其进行评估。如果模型表现良好，则不会过拟合训练集。如果在验证集上表现不佳，那么问题一定来自数据不匹配。

模型是观察的简化版。这个简化丢弃了那些不大可能泛化至新实例上的多余细节。但是，要决定丢弃哪些数据以及保留哪些数据，你必须要做出假设。例如，线性模型基于的假设就是数据基本上都是线性的，而实例与直线之间的距离都只是噪声，可以安全地忽略它们。
如果你对数据绝对没有任何假设，那么就没有理由更偏好于某个模型，这称为没有免费的午餐（No Free Lunch，NFL）定理。
要知道哪个模型最好的方法就是对所有模型进行评估，但实际上这是不可能的，因此会对数据做出一些合理的假设，然后只评估部分合理的模型。

1.如何定义机器学习？
机器学习是关于构建可以从数据中学习的系统。学习意味着在一定的性能指标下，在某些任务上会变得越来越好。
2.机器学习在哪些问题上表现突出，你能给出四种类型吗？
机器学习非常适合没有算法解答的复杂问题，它可以替代一系列需要手动调整的规则，来构建适应不断变化的环境的系统并最终帮助人类（例如，数据挖掘）。
3.什么是被标记的训练数据集？
带标签的训练集是一个包含每个实例所需解决方案（也称为标签）的训练集。
4.最常见的两种监督学习任务是什么？
回归和分类。
5.你能举出四种常见的无监督学习任务吗？
聚类、可视化、降维和关联规则学习。
6.要让一个机器人在各种未知的地形中行走，你会使用什么类型的机器学习算法？
强化学习。
7.要将顾客分成多个组，你会使用什么类型的算法？
如果你不知道如何定义组，则可以使用聚类算法（无监督学习）将客户划分为相似客户集群。但是，如果你知道你想要拥有哪些组，那么可以将每个组的许多实例提供给分类算法（有监督学习），并将所有客户分类到这些组中。
8.你会将垃圾邮件检测的问题列为监督学习还是无监督学习？
垃圾邮件检测是一个典型的有监督学习问题：向该算法提供许多电子邮件及其标签（垃圾邮件或非垃圾邮件）。
9.什么是在线学习系统？
与批量学习系统相反，在线学习系统能够进行增量学习。这使得它能够快速适应不断变化的数据和自动系统，并能够处理大量数据。
10.什么是核外学习？
核外算法可以处理无法容纳在计算机主内存中的大量数据。核外学习算法将数据分成小批量，并使用在线学习技术从这些小批量数据中学习。
11.什么类型的学习算法依赖相似度来做出预测？
基于实例的学习系统努力通过死记硬背来学习训练数据。然后，当给定一个新的实例时，它将使用相似性度量来查找最相似的实例，并利用它们来进行预测。
12.模型参数与学习算法的超参数之间有什么区别？
一个模型具有一个或多个模型参数，这些参数确定在给定一个新实例的情况下该模型将预测什么（例如，线性模型的斜率）。一种学习算法试图找到这些参数的最优值，以使该模型能很好地泛化到新实例。超参数是学习算法本身的参数，而不是模型的参数（例如，要应用正则化的数量）。
13.基于模型的学习算法搜索的是什么？它们最常使用的策略是什么？它们如何做出预测？
基于模型的学习算法搜索模型参数的最优值，以便模型可以很好地泛化到新实例。
我们通常通过最小化成本函数来训练这样的系统，该函数测量系统对训练数据进行预测时有多不准确，如果对模型进行了正则化则对模型复杂性要加上惩罚。
为了进行预测，我们使用学习算法找到的模型参数值，再将新实例的特征输入到模型的预测函数中。
14.你能给出机器学习中的四个主要挑战吗？
机器学习中的一些主要挑战是数据的缺乏、数据质量差、数据代表性不足、信息量不足、模型过于简单而欠拟合训练数据以及模型过于复杂而过拟合数据。
15.如果模型在训练数据上表现很好，但是应用到新实例上的泛化结果却很糟糕，是怎么回事？能给出三种可能的解决方案吗？
如果模型在训练数据上表现出色，但在新实例上的泛化效果很差，则该模型可能会过拟合训练数据（或者我们在训练数据上非常幸运）。过拟合的可能解决方法是获取更多数据、简化模型（选择更简单的算法，减少使用的参数或特征的数量，或对模型进行正则化）或减少训练数据中的噪声。
16.什么是测试集，为什么要使用测试集？
测试数据集是用于在启动生产环境之前，估计模型在新实例上产生的泛化误差。
17.验证集的目的是什么？
验证集是用于比较模型。这样就可以选择最佳模型并调整超参数。
18.什么是train-dev集，什么时候需要它，怎么使用？
当训练数据集与验证数据集和测试数据集中使用的数据之间不匹配时，可以使用train-dev集（该数据集应始终与模型投入生产环境后使用的数据尽可能接近）。train-dev集是训练集的一部分（模型未在其上训练过）。该模型在训练集的其他部分上进行训练，并在train-dev集和验证集上进行评估。如果模型在训练集上表现良好，但在train-dev集上表现不佳，则该模型可能过拟合训练集。如果它在训练集和train-dev集上均表现良好，但在验证集上却表现不佳，那么训练数据与验证数据和测试数据之间可能存在明显的数据不匹配，你应该尝试改善训练数据，使其看起来更像验证数据和测试数据。
19.如果你用测试集来调超参数会出现什么错误？
如果使用测试集来调整超参数，则可能会过拟合测试集，而且所测得的泛化误差会过于乐观（你可能会得到一个性能比预期差的模型）。

# 端到端的机器学习项目
本章将介绍一个端到端的项目案例。主要步骤：
1. 观察大局。
2. 获得数据。
3. 从数据探索和可视化中获得洞见。
4. 机器学习算法的数据准备。
5. 选择并训练模型。
6. 微调模型。
7. 展示解决方案。
8. 启动、监控和维护系统。

框架问题：业务目标是什么，当前的解决方案（如果有的话）。

一个序列的数据处理组件称为一个数据流水线。流水线在机器学习系统中非常普遍，因为需要大量的数据操作和数据转化才能应用。
组件通常是异步运行的。每个组件拉取大量的数据，然后进行处理，再将结果传输给另一个数据仓库。一段时间之后，流水线中的下一个组件会拉取前面的数据，并给出自己的输出，以此类推。每个组件都很独立：组件和组件之间的连接只有数据仓库。这使得整个系统非常简单易懂（在数据流图表的帮助下），不同团队可以专注于不同的组件。如果某个组件发生故障，它的下游组件还能使用前面的最后一个输出继续正常运行（至少一段时间），所以使得整体架构鲁棒性较强。
当然，从另一方面来说，如果没有实施适当的监控，坏掉的组件可能在一段时间内都无人发现，那么过期数据会导致整个系统的性能下降。

首先，需要回答框架问题：是有监督学习、无监督学习还是强化学习？是分类任务、回归任务还是其他任务？应该使用批量学习还是在线学习技术？

显然，这是一个典型的有监督学习任务，因为已经给出了标记的训练示例（每个实例都有预期的产出）。并且这也是一个典型的回归任务，因为要对某个值进行预测。更具体地说，这是一个多重回归问题，因为系统要使用多个特征进行预测。这也是一元回归问题，因为仅尝试预测单个值。如果试图预测多个值，那将是多元回归问题。最后，没有一个连续的数据流不断流进系统，所以不需要针对变化的数据做出特别调整，数据量也不是很大，不需要多个内存，所以简单的批量学习应该就能胜任。

选择性能指标。回归问题的典型性能指标是均方根误差（RMSE）。它给出了系统通常会在预测中产生多大误差，对于较大的误差，权重较高。

平均绝对误差（MAE）。

范数指标越高，它越关注大值而忽略小值。这就是RMSE对异常值比MAE更敏感的原因。但是，当离群值呈指数形式稀有时（如钟形曲线），RMSE表现非常好，通常是首选。

最后，列举和验证到目前为止（由你或者其他人）做出的假设，是一个非常好的习惯。这可以在初期检查出严重问题。

# 分类



